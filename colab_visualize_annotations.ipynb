{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffee Bean Annotation Visualizer\n",
    "\n",
    "This notebook visualizes YOLO format annotations with bounding boxes on coffee bean images.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Upload your dataset to Google Colab or mount Google Drive\n",
    "2. Run the cells below to visualize your annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install opencv-python-headless matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Dataset (Choose One Method)\n",
    "\n",
    "### Method A: Upload from Local Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the kaggle_dataset_round1.zip file\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip -q kaggle_dataset_round1.zip\n",
    "print(\"Dataset uploaded and extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method B: Mount Google Drive (if dataset is in Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update this path to your dataset location in Google Drive\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/CoffeeBeanDataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Class definitions\n",
    "CLASSES = {\n",
    "    0: \"barely-riped\",\n",
    "    1: \"over-riped\",\n",
    "    2: \"riped\",\n",
    "    3: \"semi-riped\",\n",
    "    4: \"unriped\"\n",
    "}\n",
    "\n",
    "# Colors for each class (BGR format for OpenCV)\n",
    "COLORS = {\n",
    "    0: (71, 99, 255),    # Orange/Red for barely-riped\n",
    "    1: (44, 44, 44),     # Dark gray for over-riped\n",
    "    2: (157, 166, 196),  # Brown/Pink for riped\n",
    "    3: (61, 217, 255),   # Yellow for semi-riped\n",
    "    4: (144, 238, 144)   # Light green for unriped\n",
    "}\n",
    "\n",
    "def load_yolo_annotation(label_path):\n",
    "    \"\"\"Load YOLO format annotations from file\"\"\"\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                annotations.append({\n",
    "                    'class_id': class_id,\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "    return annotations\n",
    "\n",
    "def yolo_to_corners(x_center, y_center, width, height, img_width, img_height):\n",
    "    \"\"\"Convert YOLO format to corner coordinates\"\"\"\n",
    "    x_center_px = x_center * img_width\n",
    "    y_center_px = y_center * img_height\n",
    "    width_px = width * img_width\n",
    "    height_px = height * img_height\n",
    "    \n",
    "    x1 = int(x_center_px - width_px / 2)\n",
    "    y1 = int(y_center_px - height_px / 2)\n",
    "    x2 = int(x_center_px + width_px / 2)\n",
    "    y2 = int(y_center_px + height_px / 2)\n",
    "    \n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def draw_bbox_cv2(image, annotations, show_labels=True, thickness=2):\n",
    "    \"\"\"Draw bounding boxes using OpenCV\"\"\"\n",
    "    img = image.copy()\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    \n",
    "    for ann in annotations:\n",
    "        class_id = ann['class_id']\n",
    "        x1, y1, x2, y2 = yolo_to_corners(\n",
    "            ann['x_center'], ann['y_center'],\n",
    "            ann['width'], ann['height'],\n",
    "            img_width, img_height\n",
    "        )\n",
    "        \n",
    "        # Draw rectangle\n",
    "        color = COLORS.get(class_id, (255, 255, 255))\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "        \n",
    "        # Draw label\n",
    "        if show_labels:\n",
    "            label = CLASSES.get(class_id, f\"Class {class_id}\")\n",
    "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            \n",
    "            # Draw background for text\n",
    "            cv2.rectangle(img,\n",
    "                         (x1, y1 - label_size[1] - 4),\n",
    "                         (x1 + label_size[0], y1),\n",
    "                         color, -1)\n",
    "            \n",
    "            # Draw text\n",
    "            cv2.putText(img, label, (x1, y1 - 2),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_image(image_path, label_path, figsize=(15, 10), show_labels=True):\n",
    "    \"\"\"Visualize a single image with annotations\"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load annotations\n",
    "    if Path(label_path).exists():\n",
    "        annotations = load_yolo_annotation(label_path)\n",
    "    else:\n",
    "        print(f\"Warning: No label file found at {label_path}\")\n",
    "        annotations = []\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    img_with_boxes = draw_bbox_cv2(img, annotations, show_labels=show_labels)\n",
    "    img_with_boxes_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_with_boxes_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{Path(image_path).name} - {len(annotations)} beans detected\",\n",
    "              fontsize=14, pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    class_counts = {}\n",
    "    for ann in annotations:\n",
    "        class_id = ann['class_id']\n",
    "        class_name = CLASSES.get(class_id, f\"Class {class_id}\")\n",
    "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Bean counts:\")\n",
    "    for class_name, count in sorted(class_counts.items()):\n",
    "        print(f\"   {class_name}: {count}\")\n",
    "    print(f\"   Total: {len(annotations)}\")\n",
    "\n",
    "def visualize_grid(image_dir, label_dir, num_images=4, cols=2, figsize=(15, 15),\n",
    "                   show_labels=True, random_sample=True):\n",
    "    \"\"\"Visualize multiple images in a grid\"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    label_dir = Path(label_dir)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\"))\n",
    "    \n",
    "    if random_sample:\n",
    "        image_files = random.sample(image_files, min(num_images, len(image_files)))\n",
    "    else:\n",
    "        image_files = image_files[:num_images]\n",
    "    \n",
    "    rows = (len(image_files) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    \n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [[axes]]\n",
    "    elif rows == 1 or cols == 1:\n",
    "        axes = axes.reshape(rows, cols)\n",
    "    \n",
    "    for idx, image_path in enumerate(image_files):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        ax = axes[row][col]\n",
    "        \n",
    "        # Read image\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        # Load annotations\n",
    "        label_path = label_dir / f\"{image_path.stem}.txt\"\n",
    "        if label_path.exists():\n",
    "            annotations = load_yolo_annotation(label_path)\n",
    "        else:\n",
    "            annotations = []\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        img_with_boxes = draw_bbox_cv2(img, annotations, show_labels=show_labels)\n",
    "        img_with_boxes_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display\n",
    "        ax.imshow(img_with_boxes_rgb)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{image_path.name}\\n{len(annotations)} beans\", fontsize=10)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(image_files), rows * cols):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        axes[row][col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_class_legend():\n",
    "    \"\"\"Display color legend for classes\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 3))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    colors_rgb = {\n",
    "        0: (255, 99, 71),\n",
    "        1: (44, 44, 44),\n",
    "        2: (196, 166, 157),\n",
    "        3: (255, 217, 61),\n",
    "        4: (144, 238, 144)\n",
    "    }\n",
    "    \n",
    "    y_pos = 0.8\n",
    "    for class_id in sorted(CLASSES.keys()):\n",
    "        class_name = CLASSES[class_id]\n",
    "        color = tuple(c/255 for c in colors_rgb[class_id])\n",
    "        \n",
    "        # Draw colored box\n",
    "        rect = plt.Rectangle((0.1, y_pos - 0.08), 0.1, 0.15,\n",
    "                             facecolor=color, edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add text\n",
    "        ax.text(0.25, y_pos, class_name, fontsize=14, va='center')\n",
    "        \n",
    "        y_pos -= 0.2\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.title(\"Coffee Bean Ripeness Classes\", fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Visualization functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Show Class Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one training image\n",
    "visualize_image(\n",
    "    image_path='kaggle_dataset_round1/images/train/020a77e7-106.jpg',\n",
    "    label_path='kaggle_dataset_round1/labels/train/020a77e7-106.txt',\n",
    "    figsize=(15, 10),\n",
    "    show_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Multiple Images in Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 6 random training images in a 2x3 grid\n",
    "visualize_grid(\n",
    "    image_dir='kaggle_dataset_round1/images/train',\n",
    "    label_dir='kaggle_dataset_round1/labels/train',\n",
    "    num_images=6,\n",
    "    cols=3,\n",
    "    figsize=(20, 12),\n",
    "    show_labels=True,\n",
    "    random_sample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all validation images\n",
    "visualize_grid(\n",
    "    image_dir='kaggle_dataset_round1/images/val',\n",
    "    label_dir='kaggle_dataset_round1/labels/val',\n",
    "    num_images=5,\n",
    "    cols=3,\n",
    "    figsize=(20, 10),\n",
    "    show_labels=True,\n",
    "    random_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Browse Specific Images\n",
    "\n",
    "List all available images and choose which one to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all training images\n",
    "from pathlib import Path\n",
    "\n",
    "train_images = sorted(Path('kaggle_dataset_round1/images/train').glob('*.jpg'))\n",
    "print(f\"Found {len(train_images)} training images:\\n\")\n",
    "for idx, img in enumerate(train_images, 1):\n",
    "    print(f\"{idx:2d}. {img.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image by index (change the number below)\n",
    "image_index = 0  # Change this to view different images (0 to len-1)\n",
    "\n",
    "selected_image = train_images[image_index]\n",
    "label_path = Path('kaggle_dataset_round1/labels/train') / f\"{selected_image.stem}.txt\"\n",
    "\n",
    "visualize_image(\n",
    "    image_path=selected_image,\n",
    "    label_path=label_path,\n",
    "    figsize=(15, 10),\n",
    "    show_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Specific Classes\n",
    "\n",
    "Find and visualize images containing specific bean classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images with rare classes (over-riped or barely-riped)\n",
    "def find_images_with_class(label_dir, target_class_id):\n",
    "    \"\"\"Find all images containing a specific class\"\"\"\n",
    "    label_dir = Path(label_dir)\n",
    "    matching_files = []\n",
    "    \n",
    "    for label_file in label_dir.glob('*.txt'):\n",
    "        annotations = load_yolo_annotation(label_file)\n",
    "        for ann in annotations:\n",
    "            if ann['class_id'] == target_class_id:\n",
    "                matching_files.append(label_file.stem)\n",
    "                break\n",
    "    \n",
    "    return matching_files\n",
    "\n",
    "# Find images with over-riped beans (class 1)\n",
    "over_riped_images = find_images_with_class('kaggle_dataset_round1/labels/train', 1)\n",
    "print(f\"Found {len(over_riped_images)} images with over-riped beans:\")\n",
    "for img in over_riped_images:\n",
    "    print(f\"  - {img}\")\n",
    "\n",
    "# Find images with barely-riped beans (class 0)\n",
    "barely_riped_images = find_images_with_class('kaggle_dataset_round1/labels/train', 0)\n",
    "print(f\"\\nFound {len(barely_riped_images)} images with barely-riped beans:\")\n",
    "for img in barely_riped_images:\n",
    "    print(f\"  - {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize images with over-riped beans\n",
    "if over_riped_images:\n",
    "    img_name = over_riped_images[0]\n",
    "    visualize_image(\n",
    "        image_path=f'kaggle_dataset_round1/images/train/{img_name}.jpg',\n",
    "        label_path=f'kaggle_dataset_round1/labels/train/{img_name}.txt',\n",
    "        figsize=(15, 10),\n",
    "        show_labels=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
